# Weekly Digest

Week of 2026-02-10 to 2026-02-17

## New Releases

- **vllm**: [v0.16.0](https://github.com/vllm-project/vllm/releases/tag/v0.16.0)

## PRs This Week

### pytorch
- Opened: [#175008](https://github.com/pytorch/pytorch/pull/175008) [inductor] fix blockptr advancement for broadcasted tensor (@zlin888)
- Opened: [#174759](https://github.com/pytorch/pytorch/pull/174759) [dynamo] Introduce CONSTANT_VARIABLE_FALSE singleton for Con (@ydwu4)
- Opened: [#175180](https://github.com/pytorch/pytorch/pull/175180) [rocm] Fix build_amd.py failure when MSLK submodule is missi (@radeksm)
- Opened: [#175179](https://github.com/pytorch/pytorch/pull/175179) [ROCm][CI] Update periodic-rocm-mi200.yml to use linux.rocm. (@amdfaa)
- Opened: [#174855](https://github.com/pytorch/pytorch/pull/174855) [ROCm] triton 37 disable async copy testing + llvm bump (@jataylo)
- Opened: [#175152](https://github.com/pytorch/pytorch/pull/175152) [ROCM][CI] Timeout 360 for ROCm nightly binaries (@amdfaa)
- Opened: [#174718](https://github.com/pytorch/pytorch/pull/174718) [inductor] fix allocation with deterministic guard (@kshitij12345)
- Opened: [#175079](https://github.com/pytorch/pytorch/pull/175079) Link aotriton when USE_MEM_EFF_ATTENTION is enabled for ROCm (@CalebisGross)
- Opened: [#175090](https://github.com/pytorch/pytorch/pull/175090) Cleanup forgotten Caffe2 GPU kernels tests (@radeksm)
- Opened: [#175076](https://github.com/pytorch/pytorch/pull/175076) [ROCm] auto-detect GPU architecture for cpp extensions (@CalebisGross)
- Opened: [#174748](https://github.com/pytorch/pytorch/pull/174748) Fix scatter_reduce in-place op handling in Inductor memref c (@sidt-meta)
- Opened: [#175075](https://github.com/pytorch/pytorch/pull/175075) [ROCm] allow AOTRITON_COMMIT env var to override git hash (@CalebisGross)
- Opened: [#175052](https://github.com/pytorch/pytorch/pull/175052) [ROCm] Fix test_transformerencoder_fastpath on MI300X (@roshanrateria)
- Opened: [#175047](https://github.com/pytorch/pytorch/pull/175047) [ROCm] Relax gradcheck_nondet_tol for grid_sampler ops (@roshanrateria)
- Opened: [#175051](https://github.com/pytorch/pytorch/pull/175051) [ROCm] Fix TF32 affine rotation tests on MI300X (@roshanrateria)
- Opened: [#175048](https://github.com/pytorch/pytorch/pull/175048) [ROCm] Fix flaky test_graph_concurrent_replay (@roshanrateria)
- Opened: [#175049](https://github.com/pytorch/pytorch/pull/175049) [ROCm] Fix flaky test_mem_get_info (@roshanrateria)
- Opened: [#175073](https://github.com/pytorch/pytorch/pull/175073) [inductor] Decompose mm to pointwise mul when K==1 (@romanmeta)
- Opened: [#175164](https://github.com/pytorch/pytorch/pull/175164) [ROCm] fixed random seed and device mismatch (@anvishwa-amd)
- Opened: [#174683](https://github.com/pytorch/pytorch/pull/174683) Unskipped some flex attention ROCm-specific skips (@AmdSampsa)
- Opened: [#175056](https://github.com/pytorch/pytorch/pull/175056) [ROCm] Enable mixed-precision batchnorm tests with relaxed t (@roshanrateria)
- Opened: [#175055](https://github.com/pytorch/pytorch/pull/175055) [ROCm] Fix test_profiler_cuda_sync_events for ROCTracer (@roshanrateria)
- Opened: [#175021](https://github.com/pytorch/pytorch/pull/175021) [ROCm] Fix multi-arch AOT Inductor compilation with newer Tr (@chinmaydk99)
- Opened: [#175054](https://github.com/pytorch/pytorch/pull/175054) [ROCm] Fix test_compile_kernel_advanced TF32 precision misma (@roshanrateria)
- Opened: [#175053](https://github.com/pytorch/pytorch/pull/175053) [ROCm/CUDA] Fix bfloat16 reflection padding decomposition te (@roshanrateria)

### jax
- Opened: [#35072](https://github.com/jax-ml/jax/pull/35072) A few pre-commit tweaks (@superbobry)
- Opened: [#35111](https://github.com/jax-ml/jax/pull/35111) [ROCm] Add ROCm support for eigh export backwards compatibil (@AratiGanesh)
- Opened: [#35115](https://github.com/jax-ml/jax/pull/35115) [ROCm] Add hip_threefry2x32_ffi to stable custom call target (@AratiGanesh)
- Opened: [#35102](https://github.com/jax-ml/jax/pull/35102) [ROCm] Set release rpaths to rocm so targets (@alekstheod)
- Opened: [#35091](https://github.com/jax-ml/jax/pull/35091) fixed scan crash on GPU with non-default matmul precision (@sarayusapa)
- Opened: [#34971](https://github.com/jax-ml/jax/pull/34971) [ROCm] fix the performance issue when n=1 or 2 (@cj401-amd)

### vllm
- Opened: [#34744](https://github.com/vllm-project/vllm/pull/34744) [Attention] Enable masked MHA for topk sparse attention usin (@MatthewBonanni)
- Opened: [#34574](https://github.com/vllm-project/vllm/pull/34574) [Frontend] Support multimodal inputs for late-interaction sc (@craftsangjae)
- Opened: [#34756](https://github.com/vllm-project/vllm/pull/34756) preliminary attempt on nightly rocm docker (@hongxiayang)
- Opened: [#34275](https://github.com/vllm-project/vllm/pull/34275) [ROCm] Add RDNA3 tile-size heuristic for "triton_scaled_mm"  (@monajafi-amd)
- Opened: [#34631](https://github.com/vllm-project/vllm/pull/34631) [ROCm] Make Whisper causal attention backend-agnostic (@laudney)
- Opened: [#34753](https://github.com/vllm-project/vllm/pull/34753) [ROCm][CI] Removed hard-coded attn backend requirement for Q (@AndreasKaratzas)
- Opened: [#34750](https://github.com/vllm-project/vllm/pull/34750) [Rocm][CI] Fix LM Eval Large Models (H100) test group (@charlifu)
- Opened: [#34228](https://github.com/vllm-project/vllm/pull/34228) Add unit tests for fp8 output fusion of triton_attn (@bringlein)
- Opened: [#34632](https://github.com/vllm-project/vllm/pull/34632) [ROCm] Add MXFP4 inline dequant Triton kernel for RDNA4/gfx1 (@laudney)
- Opened: [#34709](https://github.com/vllm-project/vllm/pull/34709) [ROCm] Enable wvSplitK skinny GEMM kernel for RDNA4/gfx1x de (@laudney)
- Opened: [#34741](https://github.com/vllm-project/vllm/pull/34741) [ROCm] Enable FP8 KV-cache and relax constraints for RDNA4 c (@laudney)
- Opened: [#34740](https://github.com/vllm-project/vllm/pull/34740) [ROCm] Use supports_fp8() for FP8 feature gates instead of a (@laudney)
- Opened: [#34636](https://github.com/vllm-project/vllm/pull/34636) [ROCm][Bugfix]: Only save unpadded sizes for shared_experts  (@Rohan138)
- Opened: [#34455](https://github.com/vllm-project/vllm/pull/34455) [Bugfix] Remove assert causing hipErrorStreamCaptureUnsuppor (@JadenMathias)
- Opened: [#34652](https://github.com/vllm-project/vllm/pull/34652) [AMD][CI] Fix test new_weight_syncing/rlhf.py (@rjrock)
- Opened: [#34655](https://github.com/vllm-project/vllm/pull/34655) [CI][AMD][BugFix] Skip tests in test_unquantized_backend_sel (@rasmith)
- Opened: [#34735](https://github.com/vllm-project/vllm/pull/34735) [AMD][CI] Fix test_custom_allreduce for A100 testgroup (@rjrock)
- Opened: [#34726](https://github.com/vllm-project/vllm/pull/34726) [ROCm] Enable DBO (Dynamic Batch Optimization) on ROCm (@raviguptaamd)
- Opened: [#34653](https://github.com/vllm-project/vllm/pull/34653) [BugFix] [Build] fix string literals comparison in indexer_k (@hongxiayang)
- Opened: [#34692](https://github.com/vllm-project/vllm/pull/34692) [ROCm] Enable DeepEP ROCm as all2allbackend for AMD GPUs.  (@lcskrishna)
- Opened: [#34301](https://github.com/vllm-project/vllm/pull/34301) [ROCm][Quantization] Add Composable Kernel (CK) backend supp (@dllehr-amd)
- Opened: [#34695](https://github.com/vllm-project/vllm/pull/34695) [WIP][Bugfix] Fix MLA attention crash with AWQ/GPTQ quantize (@haosdent)
- Opened: [#34688](https://github.com/vllm-project/vllm/pull/34688) [ROCm] Enable bitsandbytes quantization support on ROCm (@Abdennacer-Badaoui)
- Opened: [#34677](https://github.com/vllm-project/vllm/pull/34677) [Bugfix][CPU] Fix basic unit tests failing in CPU platforms (@jasonyanwenl)
- Opened: [#34387](https://github.com/vllm-project/vllm/pull/34387) [ROCm] Update the torch version in rocm_build.txt to use the (@SageMoore)
- Opened: [#34678](https://github.com/vllm-project/vllm/pull/34678) [GGUF][Model] Add Qwen3-Coder-Next GGUF support (@rudybear)
- Opened: [#34647](https://github.com/vllm-project/vllm/pull/34647) [ROCm] Add hardware detection for FP4 BMM to prevent MI300X  (@khairulkabir1661)
- Opened: [#34570](https://github.com/vllm-project/vllm/pull/34570) [ROCm][AITER] Fix aiter paged_attention_v1 decode for slidin (@AndreasKaratzas)
- Opened: [#34481](https://github.com/vllm-project/vllm/pull/34481) [Bugfix][Hardware][AMD] Add ahead-of-time weight dequantizat (@c0de128)
- Opened: [#34307](https://github.com/vllm-project/vllm/pull/34307) [ROCm] [CI] Add new fusion test cases that are relevant to v (@tjtanaa)
- Opened: [#34567](https://github.com/vllm-project/vllm/pull/34567) [CI] Fix ColBERT HF comparison tests on AMD CI + refactor (@AndreasKaratzas)
- Opened: [#34304](https://github.com/vllm-project/vllm/pull/34304) Improvements to wvSplitKrc skinny GEMM solution (@amd-hhashemi)
- Opened: [#34540](https://github.com/vllm-project/vllm/pull/34540) [Kernel] [Helion] [8/N] Remove fake_impl usage and inference (@gmagogsfm)
- Opened: [#34469](https://github.com/vllm-project/vllm/pull/34469) [Bugfix][Hardware][AMD] Fix string literal comparison in DIS (@c0de128)

### sglang
- Opened: [#18919](https://github.com/sgl-project/sglang/pull/18919) [bugfix?] update outdated unittest document (@SoluMilken)
- Opened: [#18862](https://github.com/sgl-project/sglang/pull/18862) Update torch to 2.10.0 (@Fridge003)
- Opened: [#18811](https://github.com/sgl-project/sglang/pull/18811) [AMD] fix: hip rotary fallback avoiding CUDA JIT (@alphabetc1)
- Opened: [#18734](https://github.com/sgl-project/sglang/pull/18734) [Docs] Refactor SGLang Diffusion Docs (@qianyue76)
- Opened: [#18911](https://github.com/sgl-project/sglang/pull/18911) [AMD] Add GLM-5 nightly test (@michaelzhang-ai)
- Opened: [#18916](https://github.com/sgl-project/sglang/pull/18916) [TorchAO] Enable TorchAO LinearMethod and TorchAOConfig (@ZhiweiYan-96)
- Opened: [#18930](https://github.com/sgl-project/sglang/pull/18930) [AMD] Unit tests for mtp in GLM-4.7  (@almaslof)
- Opened: [#18624](https://github.com/sgl-project/sglang/pull/18624) [AMD] DSR1/V3 use fp8 bmm in MLA for MI300X (@zhentaocc)
- Opened: [#18530](https://github.com/sgl-project/sglang/pull/18530) [Diffusion] [AMD] fuse norm & rope for qwen-image (@qichu-yun)
- Opened: [#18805](https://github.com/sgl-project/sglang/pull/18805) add testcase for Qwen3 235b Instruct 2507 (@mqhc2020)
- Opened: [#18733](https://github.com/sgl-project/sglang/pull/18733) Add DeepSeek V32 PD disaggregation test (@ShangmingCai)
- Opened: [#18738](https://github.com/sgl-project/sglang/pull/18738) [AMD] Test aiter regression (@yctseng0211)
- Opened: [#18708](https://github.com/sgl-project/sglang/pull/18708) Revert: [diffusion] fix: fix fsdp #18187 (@bingxche)
- Opened: [#18684](https://github.com/sgl-project/sglang/pull/18684) [AMD] Pad MoE weights and scales (@mqhc2020)
- Opened: [#18526](https://github.com/sgl-project/sglang/pull/18526) [AMD] Enable cudagraph for aiter nsa backend and add aiter i (@wufann)
- Opened: [#18656](https://github.com/sgl-project/sglang/pull/18656) [AMD] [DO NOT MERGE] Test CI (@bingxche)
- Opened: [#18571](https://github.com/sgl-project/sglang/pull/18571) ROCm: Fix AITER attention for Qwen3-Coder-Next hybrid models (@jhinpan)
- Opened: [#18623](https://github.com/sgl-project/sglang/pull/18623) fix(rocm): add parentheses to chained boolean in Triton kern (@Buywatermelon)
- Opened: [#18547](https://github.com/sgl-project/sglang/pull/18547) chore: bump sgl-kernel version to 0.3.21.post1 (@sglang-bot)
- Opened: [#18537](https://github.com/sgl-project/sglang/pull/18537) [MUSA][11/N] ci: add MUSA 4.3 kernel build and release pipel (@johnnycxm)

### aiter
- Opened: [#2056](https://github.com/ROCm/aiter/pull/2056) Enabling FPMX4 GEMM on non-FPMX4 devices (Navi31 in particul (@ekuznetsov139)
- Opened: [#2058](https://github.com/ROCm/aiter/pull/2058) fix aiter.ops.triton.rope import (@Rohan138)
- Opened: [#2049](https://github.com/ROCm/aiter/pull/2049) [TRITON] Add smoothquant int8 MoE kernel (@nsusanto)
- Opened: [#2034](https://github.com/ROCm/aiter/pull/2034) Optimize TopK-TopP Sampler Kernel (@aryaman-gupta)
- Opened: [#2053](https://github.com/ROCm/aiter/pull/2053) Support per_block for Pa PS (@ZhangLirong-amd)
- Opened: [#2055](https://github.com/ROCm/aiter/pull/2055) Silence certain warnings stemming from CK (@Micky774)
- Opened: [#2044](https://github.com/ROCm/aiter/pull/2044) [TEST] Flash Attention Integration CI from fork (@micmelesse)
- Opened: [#2052](https://github.com/ROCm/aiter/pull/2052) Prepare repository for size optimization (@sunway513)
- Opened: [#2050](https://github.com/ROCm/aiter/pull/2050) Add Model Benchmarking Tool (@lucas-santos-amd)
- Opened: [#2036](https://github.com/ROCm/aiter/pull/2036) gfx12 gemm a8w8 (@ahmed-bsod)
- Opened: [#2047](https://github.com/ROCm/aiter/pull/2047) GFX1250 Gluon MoE A4W4 Kernel (@farlukas)
- Opened: [#2028](https://github.com/ROCm/aiter/pull/2028) [MOE]: add qwen3-VL UT (@xudoyuan)
- Opened: [#2042](https://github.com/ROCm/aiter/pull/2042) upload mla_a8w8_qh64_qseqlen4_gqaratio16 co in MI300 (@minmengdie)
- Opened: [#2023](https://github.com/ROCm/aiter/pull/2023) Fix wrong path to the tune script (@amd-yashagar)
- Opened: [#2029](https://github.com/ROCm/aiter/pull/2029) [FIX] fix a16 causal mha bwd case for python api (@JaxChen29)
- Opened: [#2039](https://github.com/ROCm/aiter/pull/2039) Introduce HipKittens based nhead=128 MLA Kernel (@ruanjm)
- Opened: [#2025](https://github.com/ROCm/aiter/pull/2025) update ut (@amd-ruitang3)
- Opened: [#2018](https://github.com/ROCm/aiter/pull/2018) feat(ck_tile): add a8w8 blockscale gemm with preshuffleQuant (@amd-khushbu)
- Opened: [#2038](https://github.com/ROCm/aiter/pull/2038) gfx1250 gluon initial gemm for a8w8 MoE blockscale kernel (@nsusanto)
- Opened: [#2027](https://github.com/ROCm/aiter/pull/2027) [not ready] Fuse  rms rope blk quant kernel (@yzhou103)
- Opened: [#2019](https://github.com/ROCm/aiter/pull/2019) feat(mla_prl_ps): optimize get_ps_metadata & enhance ut (@dbyoung18)
- Opened: [#2057](https://github.com/ROCm/aiter/pull/2057) hotfix a8w8 gemm config (@valarLip)
- Opened: [#2048](https://github.com/ROCm/aiter/pull/2048) [Gluon] Unified Attention 3D development for gfx12 (@k50112113)
- Opened: [#2016](https://github.com/ROCm/aiter/pull/2016) tune triton gemm kernel for MI355 DSV3 DP+EP configuration (@inkcherry)
- Opened: [#2040](https://github.com/ROCm/aiter/pull/2040) [OPUS] enhance opus UT by adding more tests (@carlushuang)
- Opened: [#2045](https://github.com/ROCm/aiter/pull/2045) [TRITON] fav3 sage optmization (@Chi-Chu319)
- Opened: [#2041](https://github.com/ROCm/aiter/pull/2041) Rocking/fix benchmark mha fwd (@rocking5566)
- Opened: [#2043](https://github.com/ROCm/aiter/pull/2043) Fix qk_norm_rope_cache_quant ut (@ganyi1996ppo)
- Opened: [#2035](https://github.com/ROCm/aiter/pull/2035) Fix accuracy issues in top-p sampling kernels (@kliuae)
- Opened: [#2030](https://github.com/ROCm/aiter/pull/2030) fix: correct duplicate knl_name in mla_asm.csv causing PP8 f (@chun-wan)
- Opened: [#2026](https://github.com/ROCm/aiter/pull/2026) remove asm mask type (@slippedJim)
- Opened: [#2024](https://github.com/ROCm/aiter/pull/2024) [gfx942]Add new GEMM configuration files for DSKR1 (@zhentaocc)
- Opened: [#2037](https://github.com/ROCm/aiter/pull/2037) Add MI355X tuned GEMM configs for FP4 and FP8 (@sunway513)
- Opened: [#2017](https://github.com/ROCm/aiter/pull/2017) [OPUS] add opus UT (@carlushuang)
- Opened: [#2031](https://github.com/ROCm/aiter/pull/2031) Add support to dpsk-fp4 tp2/tp4(head=64/32) cases (@1am9trash)
- Opened: [#2014](https://github.com/ROCm/aiter/pull/2014) Adding gfx1150/51 to RDNA arch (@saeid-rostami)
- Opened: [#2015](https://github.com/ROCm/aiter/pull/2015) update UT (@amd-ruitang3)
- Opened: [#2022](https://github.com/ROCm/aiter/pull/2022) [CK]: Devperf fp8 ptpc tp8 bugfix (@xudoyuan)
- Opened: [#2051](https://github.com/ROCm/aiter/pull/2051) Prepare repository for size optimization (@sunway513)
- Merged: [#1954](https://github.com/ROCm/aiter/pull/1954) feat(ck_tile): add a8w8 blockscale gemm with preshuffleB sup (@kensclin)
- Merged: [#1966](https://github.com/ROCm/aiter/pull/1966) Fix known issues in mha cpp api (@slippedJim)
- Merged: [#1973](https://github.com/ROCm/aiter/pull/1973) Defer expensive build operations to build_ext.run() (@paradigm)
- Merged: [#2009](https://github.com/ROCm/aiter/pull/2009) enable hd192_128 cas br kernel in python test (@JaxChen29)
- Merged: [#1957](https://github.com/ROCm/aiter/pull/1957) fix mha fwd_v3 _s_buff_Q/K/V/D address overflow (@minmengdie)
- Merged: [#1978](https://github.com/ROCm/aiter/pull/1978) add rmsnorm CK_TILE_FLOAT_TO_BFLOAT16_DEFAULT compile config (@zhyajie)
- Merged: [#1912](https://github.com/ROCm/aiter/pull/1912) Add gfx950 mla a8w8 qh32 kernel (@slippedJim)
- Merged: [#1990](https://github.com/ROCm/aiter/pull/1990) Add `allreduce+rmsnorm+quant` fusion pass (@xytpai)
- Merged: [#1679](https://github.com/ROCm/aiter/pull/1679) Remove the input parameter "out" in gemm_a4w4 (@junhaha666)
- Merged: [#2011](https://github.com/ROCm/aiter/pull/2011) fix residual_out accuracy of  hip rmsnorm fused add (@junhaha666)
- Merged: [#2006](https://github.com/ROCm/aiter/pull/2006) [MI325] Support gfx942 i8gemm tilesize 112x256 (@feifei14119)
- Merged: [#2010](https://github.com/ROCm/aiter/pull/2010) [Fix] Solving the accuracy problem of qwen3-next ptpc with s (@yixionghuo)

### atom
- Opened: [#222](https://github.com/ROCm/ATOM/pull/222) Fix prefix caching crash: recalculate num_new_tokens after b (@ChuanLi1101)
- Opened: [#220](https://github.com/ROCm/ATOM/pull/220) Enable Triton MXFP4 MoE on gfx950 for GPT-OSS (@ChuanLi1101)
- Opened: [#212](https://github.com/ROCm/ATOM/pull/212) Fix CI container name collision for parallel matrix jobs (@sunway513)
- Opened: [#218](https://github.com/ROCm/ATOM/pull/218) Enable AllReduce+RMSNorm fusion for GPT-OSS model (@ChuanLi1101)
- Opened: [#210](https://github.com/ROCm/ATOM/pull/210) CI: Add thresholds for models accuracy tests (@gyohuangxin)
- Opened: [#208](https://github.com/ROCm/ATOM/pull/208) Not yet ready for review - Add support for Kimi-K2 and Kimi- (@thpereir)
- Opened: [#206](https://github.com/ROCm/ATOM/pull/206) Revert "CI: Use DeepSeek-R1-0528-mtp-mxfp4 models for deepse (@gyohuangxin)
- Opened: [#219](https://github.com/ROCm/ATOM/pull/219) mtp refine (@valarLip)
- Opened: [#204](https://github.com/ROCm/ATOM/pull/204) Add GPU-free unit test suite for core engine components (@sunway513)
- Opened: [#209](https://github.com/ROCm/ATOM/pull/209) Fix exclude layer (@ZhangLirong-amd)
- Opened: [#217](https://github.com/ROCm/ATOM/pull/217) Kill all Docker containers before 8gpu workloads launch (@okakarpa)
- Opened: [#216](https://github.com/ROCm/ATOM/pull/216) Revert PR #215: Remove kill-containers workflow (@okakarpa)
- Opened: [#215](https://github.com/ROCm/ATOM/pull/215) Add workflow to kill Docker containers and check ROCm on MI3 (@okakarpa)
- Opened: [#214](https://github.com/ROCm/ATOM/pull/214) Revert PR #213: Remove kill-containers workflow (@okakarpa)
- Opened: [#213](https://github.com/ROCm/ATOM/pull/213) Add workflow to kill Docker containers and check ROCm on MI3 (@okakarpa)
- Opened: [#211](https://github.com/ROCm/ATOM/pull/211) Print debug logs for inference workload (@dhonnappa-amd)
- Opened: [#207](https://github.com/ROCm/ATOM/pull/207) Engine_refine2 (@valarLip)
- Merged: [#171](https://github.com/ROCm/ATOM/pull/171) Support Qwen3-Next on ATOM Framework (@PerryZhang01)

### mori
- Opened: [#170](https://github.com/ROCm/mori/pull/170) Optimize: EP4 intranode kernel for FP4 dispatch + FP8 combin (@jhchouuu)
- Opened: [#169](https://github.com/ROCm/mori/pull/169) Feat: Enable intra-node FP4 dispatch and BF16 cast to FP8 co (@isytwu)
- Opened: [#167](https://github.com/ROCm/mori/pull/167) Feature: add fp4 support  (@TianDi101)
- Opened: [#166](https://github.com/ROCm/mori/pull/166) Feat: Fp8 direct cast in Combine (@maning00)

## New Issues This Week

### pytorch
- [#175188](https://github.com/pytorch/pytorch/issues/175188) [MPS] tanh/sigmoid/silu backward produces wrong gradients on (@npinto)
- [#175187](https://github.com/pytorch/pytorch/issues/175187) [MPS] sort and digamma produce wrong results on non-contiguo (@npinto)
- [#175192](https://github.com/pytorch/pytorch/issues/175192) [MPS] linalg.solve backward gives wrong gradients for both A (@npinto)
- [#175190](https://github.com/pytorch/pytorch/issues/175190) [MPS] AvgPool2d/AdaptiveAvgPool2d backward crashes (SIGABRT) (@npinto)
- [#175189](https://github.com/pytorch/pytorch/issues/175189) [MPS] BatchNorm2d backward produces wildly wrong weight grad (@npinto)
- [#175182](https://github.com/pytorch/pytorch/issues/175182) RuntimeError not raised on Thor/Spark in `test_float8_basics (@gderossi)
- [#175145](https://github.com/pytorch/pytorch/issues/175145) [torch.disitributed] Persistent Deadlock when overlapping NC (@ilmarkov)
- [#174695](https://github.com/pytorch/pytorch/issues/174695) [Inductor] Missing host-side synchronization after non-block (@jeffdaily)
- [#174884](https://github.com/pytorch/pytorch/issues/174884) Inductor BF16 training crashes with autograd INTERNAL ASSERT (@kumartanmay-28)
- [#174949](https://github.com/pytorch/pytorch/issues/174949) [vllm] CUBLAS_STATUS_INVALID_VALUE in cublasGemmEx after upg (@ZJY0516)
- [#175025](https://github.com/pytorch/pytorch/issues/175025) Mega-Cache generate mismatched guard states when loading the (@liyineeek-source)
- [#175160](https://github.com/pytorch/pytorch/issues/175160) check if file exsits before hipifying (@trixirt)
- [#174682](https://github.com/pytorch/pytorch/issues/174682) spin lint doesn't regenerate cuda headers (@albanD)
- [#175058](https://github.com/pytorch/pytorch/issues/175058) torch.compile VRAM usage regression between 2.9.1 and 2.10.0 (@dxqb)
- [#175057](https://github.com/pytorch/pytorch/issues/175057) torch.compile / Inductor generates invalid C++ (undeclared z (@griffinstalha)
- [#174794](https://github.com/pytorch/pytorch/issues/174794) REGRESSION: Shadowed variable name crashes `torch.compile` i (@rwkeane)
- [#174984](https://github.com/pytorch/pytorch/issues/174984) `torch.fft.rfft` errors out with MKL FFT error when given an (@SilentTester73)
- [#174763](https://github.com/pytorch/pytorch/issues/174763) torch._grouped_mm is not autocast-compatible, causes dtype m (@Mr-Neutr0n)
- [#175064](https://github.com/pytorch/pytorch/issues/175064) DISABLED test_index (__main__.DistTensorOpsTest) (@seemethere)
- [#174986](https://github.com/pytorch/pytorch/issues/174986) `torch.istft` returns an unhelpful internal error (@SilentTester73)
- [#174985](https://github.com/pytorch/pytorch/issues/174985) `torch.isclose` fails with a broadcast when comparing with ` (@SilentTester73)
- [#174939](https://github.com/pytorch/pytorch/issues/174939) `torch.nn.functional.scaled_dot_product_attention` crashes w (@Nyovelt)
- [#174913](https://github.com/pytorch/pytorch/issues/174913) Test: TestLinalg.test_tensorinv (@jeffdaily)
- [#174876](https://github.com/pytorch/pytorch/issues/174876) [export] while_loop raises GuardOnDataDependentSymNode if an (@Callidior)

### vllm
- [#34583](https://github.com/vllm-project/vllm/issues/34583) [Bug] Missing Vocabulary Validation for MTP and Eagle Specul (@amadhan882)
- [#34755](https://github.com/vllm-project/vllm/issues/34755) Qwen3-Coder-Next-FP8 with tool calling causes system hard-fr (@zaidorx)
- [#34752](https://github.com/vllm-project/vllm/issues/34752) [Bug]: Improve `--kv-cache-dtype` behavior when checkpoint s (@pavanimajety)
- [#34634](https://github.com/vllm-project/vllm/issues/34634) [Bug]: SharedStorageConnector: vectorized_gather_kernel asse (@mmkamani7)
- [#34650](https://github.com/vllm-project/vllm/issues/34650) Bug: Speculative Decoding (MTP) Causes </think> Detection Fa (@cicirori)
- [#34437](https://github.com/vllm-project/vllm/issues/34437) [Bug]: Qwen3 Next with heterogeneous GPU (FP8 overflow?) (@Nepherpitou)
- [#34619](https://github.com/vllm-project/vllm/issues/34619) [Bug]: Qwen3.5. `illegal memory access` (@vadiklyutiy)
- [#34705](https://github.com/vllm-project/vllm/issues/34705) [Bug]: Old torch compile files cause poor CPU utilisation (@almayne)
- [#34694](https://github.com/vllm-project/vllm/issues/34694) [Bug]: BF16 NVFP4 Marlin produces garbled output on GPUs wit (@ricky-chaoju)
- [#34449](https://github.com/vllm-project/vllm/issues/34449) [Bug]: GLM-5-FP8 malformed tool calls (@TALLEC-Scott)
- [#34256](https://github.com/vllm-project/vllm/issues/34256) [Model Performance SIG]: Improve MoE Oracle (@robertgshaw2-redhat)
- [#34573](https://github.com/vllm-project/vllm/issues/34573) [Installation/Runtime]: Linux ROCM7 /  RuntimeError: No HIP  (@NickJLange)
- [#34331](https://github.com/vllm-project/vllm/issues/34331) [RFC]: Ahead of time dequantization of weights for quantizat (@fxmarty-amd)
- [#34641](https://github.com/vllm-project/vllm/issues/34641) [ROCm] Default VLLM_ROCM_USE_AITER_FP4BMM=True crashes on MI (@khairulkabir1661)
- [#34637](https://github.com/vllm-project/vllm/issues/34637) [CI Failure]:  mi325_1: Entrypoints Integration Test (API Se (@AndreasKaratzas)
- [#34561](https://github.com/vllm-project/vllm/issues/34561) [Bug]: GLM-4.7-Flash-AWQ fails with AttributeError: 'ColumnP (@eugr)
- [#34399](https://github.com/vllm-project/vllm/issues/34399) [Bug]: Nemotron 3 (all quants) take a LONG time to load (@jiangwu300)
- [#34579](https://github.com/vllm-project/vllm/issues/34579) [Performance]: vLLM's throughput lags behind llama.cpp for s (@kathirvel-balakrishnan)
- [#34545](https://github.com/vllm-project/vllm/issues/34545) [Installation]: unrecognized arguments: --omni (@HenryBao91)

### sglang
- [#18812](https://github.com/sgl-project/sglang/issues/18812) [Bug] RotaryEmbedding fallback requires CUDA_HOME on HIP (@alphabetc1)
- [#18749](https://github.com/sgl-project/sglang/issues/18749) [Bug] DP Attention FP4 Disagg AMD is broken (@functionstackx)

### aiter
- [#2054](https://github.com/ROCm/aiter/issues/2054) [Feature]: Migrate Python bindings from pybind11 to apache-t (@carlushuang)
- [#2046](https://github.com/ROCm/aiter/issues/2046) Questions about topk_per_row_kernel in topk_plain_kernels.cu (@zjin-lcf)
- [#2033](https://github.com/ROCm/aiter/issues/2033) [Feature]: Add OPUS tests in Aiter CI (@gyohuangxin)
- [#2021](https://github.com/ROCm/aiter/issues/2021) [Issue]: layernorm build error (@kurapov-peter)

### atom
- [#221](https://github.com/ROCm/ATOM/issues/221) [Issue]: ATOM fails on Qwen3 model when the flag "--enable_p (@vecheruk-amd)

### mori
- [#168](https://github.com/ROCm/mori/issues/168) [Issue]: MORI-EP bug on MI300X+CX7 (@TianDi101)
