# Weekly Digest

Week of 2026-02-13 to 2026-02-20

## New Releases

- **vllm**: [v0.16.0](https://github.com/vllm-project/vllm/releases/tag/v0.16.0)

## PRs This Week

### pytorch
- Opened: [#175285](https://github.com/pytorch/pytorch/pull/175285) [Inductor] Allow subgraphs to be benchmarked with async pipe (@PaulZhang12)
- Opened: [#175073](https://github.com/pytorch/pytorch/pull/175073) [inductor] Decompose mm to pointwise mul when K==1 (@romanmeta)
- Opened: [#175343](https://github.com/pytorch/pytorch/pull/175343) [flex] Fix equality of MaskMod for multiple tracing in aot (@IvanKobzarev)
- Opened: [#175180](https://github.com/pytorch/pytorch/pull/175180) [rocm] Fix build_amd.py failure when MSLK submodule is missi (@radeksm)
- Opened: [#174989](https://github.com/pytorch/pytorch/pull/174989) [Inductor] Add conv1d triton template (@kqfu)
- Opened: [#175164](https://github.com/pytorch/pytorch/pull/175164) [ROCm] fixed random seed and device mismatch (@anvishwa-amd)
- Opened: [#175383](https://github.com/pytorch/pytorch/pull/175383) [1/N] Migrate more ops to per-operator headers (@malfet)
- Opened: [#175386](https://github.com/pytorch/pytorch/pull/175386) [audio hash update] update the pinned audio hash (@pytorchupdatebot)
- Opened: [#175356](https://github.com/pytorch/pytorch/pull/175356) Fix scatter_reduce in-place op handling in Inductor memref c (@sidt-meta)
- Opened: [#175278](https://github.com/pytorch/pytorch/pull/175278) [inductor] Apply custom op autotuning to aten.mm (@eellison)
- Opened: [#175053](https://github.com/pytorch/pytorch/pull/175053) [ROCm/CUDA] Fix bfloat16 reflection padding decomposition te (@roshanrateria)
- Opened: [#175377](https://github.com/pytorch/pytorch/pull/175377) [ROCm]Handle capture-time HIP event query errors in NCCL wat (@chinmaydk99)
- Opened: [#175371](https://github.com/pytorch/pytorch/pull/175371) [DO NOT MERGE] test linalg for rocm (@ethanwee1)
- Opened: [#175159](https://github.com/pytorch/pytorch/pull/175159) [ROCm] forward fix #174087, take 4 (@pytorchbot)
- Opened: [#175335](https://github.com/pytorch/pytorch/pull/175335) [inductor] Fix shape display for extern/template/nop nodes i (@dshi7)
- Opened: [#175387](https://github.com/pytorch/pytorch/pull/175387) [2/N] Port  register_special_ops.cpp to use per-operator hea (@malfet)
- Opened: [#175056](https://github.com/pytorch/pytorch/pull/175056) [ROCm] Enable mixed-precision batchnorm tests with relaxed t (@roshanrateria)
- Opened: [#175055](https://github.com/pytorch/pytorch/pull/175055) [ROCm] Fix test_profiler_cuda_sync_events for ROCTracer (@roshanrateria)
- Opened: [#175303](https://github.com/pytorch/pytorch/pull/175303) [ROCM] Refactor BFloat16 implementation for native usage of  (@anatoliylitv)
- Opened: [#175152](https://github.com/pytorch/pytorch/pull/175152) [ROCM][CI] Timeout 360 for ROCm nightly binaries (@amdfaa)
- Opened: [#175049](https://github.com/pytorch/pytorch/pull/175049) [ROCm] Fix flaky test_mem_get_info (@roshanrateria)
- Opened: [#175360](https://github.com/pytorch/pytorch/pull/175360) [DO NOT MERGE] test rocm-nightly pr (@ethanwee1)
- Opened: [#175047](https://github.com/pytorch/pytorch/pull/175047) [ROCm] Relax gradcheck_nondet_tol for grid_sampler ops (@roshanrateria)
- Opened: [#175097](https://github.com/pytorch/pytorch/pull/175097) [DO NOT REBASE][ROCm][Inductor] New Inductor benchmarker bas (@naromero77amd)
- Opened: [#175299](https://github.com/pytorch/pytorch/pull/175299) [benchmark] Skip pytorch_CycleGAN_and_pix2pix from inductor  (@pytorchbot)
- Opened: [#175148](https://github.com/pytorch/pytorch/pull/175148) [ROCm] Remove stale paths from hipify build script (@CalebisGross)
- Opened: [#175286](https://github.com/pytorch/pytorch/pull/175286) [ROCm] No-fence in normalization kernel (@anatoliylitv)
- Opened: [#175095](https://github.com/pytorch/pytorch/pull/175095) Revert "[CI] Enable TIMM pretrained model caching on shared  (@jeffdaily)
- Opened: [#175094](https://github.com/pytorch/pytorch/pull/175094) Revert "[fix] DISABLED test_index (__main__.DistTensorOpsTes (@jeffdaily)
- Opened: [#175096](https://github.com/pytorch/pytorch/pull/175096) Update inductor expected accuracy files (@pytorchbot)

### jax
- Opened: [#35251](https://github.com/jax-ml/jax/pull/35251) [WIP ROCm] Migrate rocm wheel build (@alekstheod)
- Opened: [#35102](https://github.com/jax-ml/jax/pull/35102) [ROCm] Set release rpaths to rocm so targets (@alekstheod)
- Opened: [#35115](https://github.com/jax-ml/jax/pull/35115) [ROCm] Add hip_threefry2x32_ffi to stable custom call target (@AratiGanesh)
- Opened: [#35111](https://github.com/jax-ml/jax/pull/35111) [ROCm] Add ROCm support for eigh export backwards compatibil (@AratiGanesh)
- Merged: [#31768](https://github.com/jax-ml/jax/pull/31768) [ROCm] Support lowering through PJRT_Triton_Extension (@amd-jianli12)
- Merged: [#34829](https://github.com/jax-ml/jax/pull/34829) [ROCm] Add ROCm LU solver to backward compatibility tests (@AratiGanesh)
- Merged: [#34929](https://github.com/jax-ml/jax/pull/34929) [ROCm] Modified `test_with_memory_space` to include ROCm tes (@tsrw2048)
- Merged: [#34966](https://github.com/jax-ml/jax/pull/34966) [ROCm] Skip test_batch_axis_sharding_jvp (@AratiGanesh)
- Merged: [#34561](https://github.com/jax-ml/jax/pull/34561) [ROCm] Enable ToeplitzSymmetricConstruction and condition nu (@tsrw2048)
- Merged: [#34870](https://github.com/jax-ml/jax/pull/34870) [ROCm] Add ROCm backward compatibility test for lu_pivots_to (@AratiGanesh)
- Merged: [#34501](https://github.com/jax-ml/jax/pull/34501) [ROCm] Enable cuda array interface test on ROCm (@magaonka-amd)
- Merged: [#34894](https://github.com/jax-ml/jax/pull/34894) Add ROCm backward compatibility test for cholesky solver (@AratiGanesh)
- Merged: [#35011](https://github.com/jax-ml/jax/pull/35011) [ROCm] Remove incorrect ROCm lowering for scaled_matmul to p (@Ruturaj4)
- Merged: [#33157](https://github.com/jax-ml/jax/pull/33157) [ROCm] Resolve undefined behavior in bitshift unit test (@mminutoli)

### vllm
- Opened: [#34541](https://github.com/vllm-project/vllm/pull/34541) [ROCM] Optimize ROCM_AITER_FA spec decode eagle performance (@jennyyyyzhen)
- Opened: [#34934](https://github.com/vllm-project/vllm/pull/34934) [Bugfix][CI] fix typos (@1195343015)
- Opened: [#34922](https://github.com/vllm-project/vllm/pull/34922) [ROCm][CI] Loosen RemoteOpenAIServer Startup Timeout (@micah-wil)
- Opened: [#34636](https://github.com/vllm-project/vllm/pull/34636) [ROCm][Bugfix]: Only save unpadded sizes for shared_experts  (@Rohan138)
- Opened: [#34740](https://github.com/vllm-project/vllm/pull/34740) [ROCm] Use supports_fp8() for FP8 feature gates instead of a (@laudney)
- Opened: [#34574](https://github.com/vllm-project/vllm/pull/34574) [Frontend] Support multimodal inputs for late-interaction sc (@craftsangjae)
- Opened: [#34907](https://github.com/vllm-project/vllm/pull/34907) [ROCm][P/D][MORI][BugFix] Add transfer_id for moriio_connect (@rasmith)
- Opened: [#34931](https://github.com/vllm-project/vllm/pull/34931) [AMD][CI] Support Triton attention with ExampleConnector (@rjrock)
- Opened: [#34709](https://github.com/vllm-project/vllm/pull/34709) [ROCm] Enable wvSplitK skinny GEMM kernel for RDNA4/gfx1x de (@laudney)
- Opened: [#34923](https://github.com/vllm-project/vllm/pull/34923) [ROCm][CI] Added MI325 mirrors (@AndreasKaratzas)
- Opened: [#34927](https://github.com/vllm-project/vllm/pull/34927) [Bugfix][Kernel] Fix activation_kernels.cu build failure on  (@FloatingVertex)
- Opened: [#34567](https://github.com/vllm-project/vllm/pull/34567) [CI] Fix ColBERT HF comparison tests on AMD CI + refactor (@AndreasKaratzas)
- Opened: [#34544](https://github.com/vllm-project/vllm/pull/34544) [RL] Pause and Resume for DPEP (@hao-aaron)
- Opened: [#34688](https://github.com/vllm-project/vllm/pull/34688) [ROCm] Enable bitsandbytes quantization support on ROCm (@Abdennacer-Badaoui)
- Opened: [#34918](https://github.com/vllm-project/vllm/pull/34918) Change targets for AMD build in the "CI" pipeline (@Alexei-V-Ivanov-AMD)
- Opened: [#34599](https://github.com/vllm-project/vllm/pull/34599) [ROCm][CI] Fix spec decode logprobs flakiness and parametriz (@AndreasKaratzas)
- Opened: [#34798](https://github.com/vllm-project/vllm/pull/34798) [Mamba1] - Kernel Level Chunk Alignment for Prefix Caching (@Josephasafg)
- Opened: [#34540](https://github.com/vllm-project/vllm/pull/34540) [Kernel] [Helion] [8/N] Remove fake_impl usage and inference (@gmagogsfm)
- Opened: [#34631](https://github.com/vllm-project/vllm/pull/34631) [ROCm] Make Whisper causal attention backend-agnostic (@laudney)
- Opened: [#34632](https://github.com/vllm-project/vllm/pull/34632) [ROCm] Add MXFP4 inline dequant Triton kernel for RDNA4/gfx1 (@laudney)
- Opened: [#34750](https://github.com/vllm-project/vllm/pull/34750) [Rocm][CI] Fix LM Eval Large Models (H100) test group (@charlifu)
- Opened: [#34652](https://github.com/vllm-project/vllm/pull/34652) [AMD][CI] Skip test new_weight_syncing/rlhf.py (@rjrock)
- Opened: [#34644](https://github.com/vllm-project/vllm/pull/34644) [release 2.11] Update to torch 2.11-rc1 (@atalman)
- Opened: [#34839](https://github.com/vllm-project/vllm/pull/34839) [ROCm][CI] Cleaning and restructuring amd-ci legacy pipeline (@AndreasKaratzas)
- Opened: [#34885](https://github.com/vllm-project/vllm/pull/34885) [CI/Build] Try to make beam search test less flaky (@DarkLight1337)
- Opened: [#34677](https://github.com/vllm-project/vllm/pull/34677) [Bugfix][CPU] Fix basic unit tests failing in CPU platforms (@jasonyanwenl)
- Opened: [#34878](https://github.com/vllm-project/vllm/pull/34878) [ROCm][Test] Fix beam search determinism failures from batch (@AndreasKaratzas)
- Opened: [#34879](https://github.com/vllm-project/vllm/pull/34879) [ROCm][CI] Removing all blocking labels from MI355 until sta (@AndreasKaratzas)
- Opened: [#34570](https://github.com/vllm-project/vllm/pull/34570) [ROCm][AITER] Fix aiter paged_attention_v1 decode for slidin (@AndreasKaratzas)
- Opened: [#34647](https://github.com/vllm-project/vllm/pull/34647) [ROCm] Add hardware detection for FP4 BMM to prevent MI300X  (@khairulkabir1661)
- Opened: [#34735](https://github.com/vllm-project/vllm/pull/34735) [AMD][CI] Fix test_custom_allreduce for A100 testgroup (@rjrock)
- Opened: [#34655](https://github.com/vllm-project/vllm/pull/34655) [CI][AMD][BugFix] Skip tests in test_unquantized_backend_sel (@rasmith)
- Opened: [#34776](https://github.com/vllm-project/vllm/pull/34776) [WIP] Add Warmup to `vllm bench throughput` (@micah-wil)
- Opened: [#34825](https://github.com/vllm-project/vllm/pull/34825) [CI] temporarily disable multi-node tests (@robertgshaw2-redhat)
- Opened: [#34753](https://github.com/vllm-project/vllm/pull/34753) [ROCm][CI] Removed hard-coded attn backend requirement for Q (@AndreasKaratzas)
- Opened: [#34653](https://github.com/vllm-project/vllm/pull/34653) [BugFix] [Build] fix string literals comparison in indexer_k (@hongxiayang)
- Opened: [#34726](https://github.com/vllm-project/vllm/pull/34726) [ROCm] Enable DBO (Dynamic Batch Optimization) on ROCm (@raviguptaamd)
- Opened: [#34741](https://github.com/vllm-project/vllm/pull/34741) [ROCm] Enable FP8 KV-cache and relax constraints for RDNA4 c (@laudney)
- Opened: [#34507](https://github.com/vllm-project/vllm/pull/34507) [Bugfix] Fix fused MoE int32 overflow in stride*offset witho (@haosdent)
- Opened: [#34566](https://github.com/vllm-project/vllm/pull/34566) [CI][Metrics] Stabilize tests with polling and subprocess gu (@AndreasKaratzas)
- Opened: [#34589](https://github.com/vllm-project/vllm/pull/34589) [ROCm][CI] Fix plugins test group; updating terratorch and d (@AndreasKaratzas)
- Opened: [#34629](https://github.com/vllm-project/vllm/pull/34629) Targeting the MI355 agent pool with all existing tests (@Alexei-V-Ivanov-AMD)
- Opened: [#34590](https://github.com/vllm-project/vllm/pull/34590) [CI][Frontend] Return 422 instead of 500 for invalid Anthrop (@AndreasKaratzas)
- Opened: [#34537](https://github.com/vllm-project/vllm/pull/34537) [Kernels] Fix Helion GPU utils to use platform-agnostic devi (@AndreasKaratzas)
- Opened: [#34538](https://github.com/vllm-project/vllm/pull/34538) [ROCm][CI] Guard sparse MLA backend imports for ROCm compati (@AndreasKaratzas)
- Opened: [#34543](https://github.com/vllm-project/vllm/pull/34543) [Bugfix] Fix ROCm UVA CPU weight offloading broken by #32993 (@AndreasKaratzas)
- Merged: [#32877](https://github.com/vllm-project/vllm/pull/32877) [Bugfix][Hardware][AMD] Fix ROCM_AITER_FA speculative decodi (@c0de128)
- Merged: [#33739](https://github.com/vllm-project/vllm/pull/33739) [CI][AMD][BugFix][P/D] Add default_vllm_config to test_morii (@rasmith)
- Merged: [#32993](https://github.com/vllm-project/vllm/pull/32993) [Feature] Support CPU Offloading without Pytorch Pinned Memo (@wzhao18)
- Merged: [#26535](https://github.com/vllm-project/vllm/pull/26535) [Bugfix] Convert untraceable GroupShape to list for AMD impl (@Lucaskabela)
- Merged: [#23207](https://github.com/vllm-project/vllm/pull/23207) [Misc][qwen2_5_vl][torch.compile] Enable `supports_torch_com (@Lucaskabela)
- Merged: [#30709](https://github.com/vllm-project/vllm/pull/30709) [Misc][LLaMa4] Compile LLaMa Vision Encoder (@Lucaskabela)
- Merged: [#31748](https://github.com/vllm-project/vllm/pull/31748) [Misc][BE] Type coverage for vllm/compilation [3/3] (@Lucaskabela)
- Merged: [#34181](https://github.com/vllm-project/vllm/pull/34181) [CI][AMD][BugFix] Use torch.testing.assert_close instead of  (@rasmith)
- Merged: [#34455](https://github.com/vllm-project/vllm/pull/34455) [Bugfix] Remove assert causing hipErrorStreamCaptureUnsuppor (@JadenMathias)
- Merged: [#34228](https://github.com/vllm-project/vllm/pull/34228) Add unit tests for fp8 output fusion of triton_attn (@bringlein)
- Merged: [#34324](https://github.com/vllm-project/vllm/pull/34324) Fixed whisper CPU test that does not spawn properly. (@almayne)
- Merged: [#34320](https://github.com/vllm-project/vllm/pull/34320) [Bugfix] Fix Dynamo unexpected keyword argument  (@samutamm)
- Merged: [#34279](https://github.com/vllm-project/vllm/pull/34279) [Bugfix] Fix fused MoE IMA (sans chunking) by using int64 fo (@tlrmchlsmth)
- Merged: [#33493](https://github.com/vllm-project/vllm/pull/33493) Perf tuning and expansion of cases covered for wvSplitKrc (@amd-hhashemi)
- Merged: [#32183](https://github.com/vllm-project/vllm/pull/32183) [MM Encoder] Add Triton ViT attention backend (@Isotr0py)
- Merged: [#34468](https://github.com/vllm-project/vllm/pull/34468) [CI][Entrypoints] Validate detokenize token IDs to prevent i (@AndreasKaratzas)
- Merged: [#34378](https://github.com/vllm-project/vllm/pull/34378) Use paged_attention_v1 for sliding window decode in rocm_ait (@iseeyuan)
- Merged: [#34294](https://github.com/vllm-project/vllm/pull/34294) [CI] Heavy refactoring of Voxtral multimodal audio model tes (@AndreasKaratzas)
- Merged: [#34454](https://github.com/vllm-project/vllm/pull/34454) [Bugfix]: Fix structured output in multi-turn gpt-oss (@bbrowning)
- Merged: [#34047](https://github.com/vllm-project/vllm/pull/34047) [ROCm][CI] Fix serving tokens test failures (@AndreasKaratzas)
- Merged: [#32458](https://github.com/vllm-project/vllm/pull/32458) [CI][BugFix] Fix silent failure in shellcheck hook and basel (@junuxyz)
- Merged: [#34130](https://github.com/vllm-project/vllm/pull/34130) [Perf] fused_moe: add int4_w4a16 benchmark support and tunin (@mgehre-amd)

### sglang
- Opened: [#19007](https://github.com/sgl-project/sglang/pull/19007) [AMD] Replace msgpack with msgspec in MORI-IO (@Duyi-Wang)
- Opened: [#18992](https://github.com/sgl-project/sglang/pull/18992) [DONOT MERGE][AMD] Enable ROCm kvcache JIT path and add AMD  (@hubertlu-tw)
- Opened: [#18911](https://github.com/sgl-project/sglang/pull/18911) [AMD] [DO NOT MERGE] [GLM-5 Day 0] Add GLM-5 nightly test (@michaelzhang-ai)
- Opened: [#19012](https://github.com/sgl-project/sglang/pull/19012) [AMD] fix: ensure scheme attribute exists before type checki (@Duyi-Wang)
- Opened: [#18930](https://github.com/sgl-project/sglang/pull/18930) [AMD] Unit tests for mtp in GLM-4.7  (@almaslof)
- Opened: [#18978](https://github.com/sgl-project/sglang/pull/18978) [AMD]  Fix mi35x dsv32 mtp nightly (@bingxche)
- Opened: [#18982](https://github.com/sgl-project/sglang/pull/18982) [Doc] Add `flashinfer_deepgemm` to `--fp8-gemm-backend` (@mmangkad)
- Opened: [#18972](https://github.com/sgl-project/sglang/pull/18972) [AMD] ROCm7.2: Add /sgl-workspace/aiter to PYTHONPATH (@HaiShaw)
- Opened: [#18862](https://github.com/sgl-project/sglang/pull/18862) Update torch to 2.10.0 (@Fridge003)
- Opened: [#18919](https://github.com/sgl-project/sglang/pull/18919) [bugfix?] update outdated unittest document (@SoluMilken)
- Opened: [#18916](https://github.com/sgl-project/sglang/pull/18916) [TorchAO] Enable TorchAO LinearMethod and TorchAOConfig (@ZhiweiYan-96)
- Opened: [#18761](https://github.com/sgl-project/sglang/pull/18761) [AMD] Fix nightly 1-GPU test failures and bench_serving regr (@michaelzhang-ai)
- Opened: [#18920](https://github.com/sgl-project/sglang/pull/18920) ROCm use rotary_embedding from sgl-kernel (@HaiShaw)
- Opened: [#18922](https://github.com/sgl-project/sglang/pull/18922) Revert "[AMD] Fix RotaryEmbedding crash on AMD/ROCm (regress (@HaiShaw)
- Opened: [#18903](https://github.com/sgl-project/sglang/pull/18903) [AMD] Fix RotaryEmbedding crash on AMD/ROCm (regression from (@michaelzhang-ai)
- Opened: [#18860](https://github.com/sgl-project/sglang/pull/18860) update pre-commit config (@SoluMilken)
- Opened: [#18753](https://github.com/sgl-project/sglang/pull/18753) [AMD] Fix/qwen3 5 amd rope cutedsl fallback (@andyluo7)
- Opened: [#18836](https://github.com/sgl-project/sglang/pull/18836) [AMD] Fix sgl-model-gateway Build Errors in ROCm Docker Rele (@bingxche)
- Opened: [#18805](https://github.com/sgl-project/sglang/pull/18805) add testcase for Qwen3 235b Instruct 2507 (@mqhc2020)
- Opened: [#18788](https://github.com/sgl-project/sglang/pull/18788) Cleanup unused rerun stages (@ispobock)
- Merged: [#18252](https://github.com/sgl-project/sglang/pull/18252) [4/N] Quantization Refactor: Quark MoE schemes (@TamirBaydasov)
- Merged: [#17554](https://github.com/sgl-project/sglang/pull/17554) Kernel: optimize decoding metadata in NSA multi-spec backend (@Johnsonms)
- Merged: [#17993](https://github.com/sgl-project/sglang/pull/17993) [3/N] Quantization Refactor: ModelSlim MoE schemes (@TamirBaydasov)
- Merged: [#18395](https://github.com/sgl-project/sglang/pull/18395) [Doc] Convert the speculative decoding notebook to markdow (@alphabetc1)
- Merged: [#17503](https://github.com/sgl-project/sglang/pull/17503) [2/N] Quantization Refactor: Compressed tensors MoE schemes (@TamirBaydasov)
- Merged: [#18437](https://github.com/sgl-project/sglang/pull/18437) [AMD] MORI-EP inter kernel type switch (@Duyi-Wang)
- Merged: [#18496](https://github.com/sgl-project/sglang/pull/18496) [FIX] Correct JIT kernel compilation on newer GPUs with outd (@muse-coder)
- Merged: [#18602](https://github.com/sgl-project/sglang/pull/18602) [CI] feat: add early exit to wait_for_server when process di (@alphabetc1)
- Merged: [#18456](https://github.com/sgl-project/sglang/pull/18456) [diffusion][MUSA] fix: MUSA platform breakage caused by PR # (@yeahdongcn)
- Merged: [#18480](https://github.com/sgl-project/sglang/pull/18480) Added cuda availability guard (@mattteochen)
- Merged: [#18654](https://github.com/sgl-project/sglang/pull/18654) [schedule] Fix streaming return of customized_info (@yinghai)
- Merged: [#18619](https://github.com/sgl-project/sglang/pull/18619) [diffusion] feat: support tp for qwen-image-edit-2511 (@xiaoyewww)
- Merged: [#18716](https://github.com/sgl-project/sglang/pull/18716) [AMD] Fix Multimodal Test 1 GPU (@bingxche)

### triton
- Opened: [#9522](https://github.com/triton-lang/triton/pull/9522) [AMD] Update gfx1250 MXFP FA example kernel (@borontion)
- Opened: [#9506](https://github.com/triton-lang/triton/pull/9506) [AMD] Fix TensorDescType shared memory size for WS captures (@PMylon)
- Opened: [#9519](https://github.com/triton-lang/triton/pull/9519) [AMD][NFC] Fix error message for wmma scale (@borontion)
- Opened: [#9509](https://github.com/triton-lang/triton/pull/9509) [AMD] Enable supportBitwidth{16|32}Elementwise in TargetInfo (@antiagainst)
- Opened: [#9513](https://github.com/triton-lang/triton/pull/9513) [AMD][GLUON] Allow DistributedLayouts in AsyncCopy and Buffe (@AlexAUT)
- Opened: [#9512](https://github.com/triton-lang/triton/pull/9512) [AMD][NFC] Emit error for buffer_load_to_local on gfx1250 (@AlexAUT)
- Opened: [#9502](https://github.com/triton-lang/triton/pull/9502) [AMD][BACKEND] Cherry pick pr 9487 to rel 3.7 (@AmdSampsa)
- Opened: [#9496](https://github.com/triton-lang/triton/pull/9496) [AMD][gfx1250] Fix tensordesc index after kernel launch chan (@antiagainst)
- Opened: [#9494](https://github.com/triton-lang/triton/pull/9494) Revert "[AMD] Don't use s_waitcnt to lower global barrier fo (@antiagainst)
- Opened: [#9490](https://github.com/triton-lang/triton/pull/9490) [AMD]Fix a bug about CGA-layout in AccelerateAMDMatmul.  (@yangshuxin)
- Opened: [#9455](https://github.com/triton-lang/triton/pull/9455) [AMD] Enable floating-point sanitizer (FpSan) support (@kelesvol)
- Opened: [#9487](https://github.com/triton-lang/triton/pull/9487) [AMD][BACKEND] Properly handle PointerTypes in v_perm Conver (@AlexAUT)
- Opened: [#9449](https://github.com/triton-lang/triton/pull/9449) [AMD] Added hw FP upcast conversions for gfx1250 (@ravil-mobile)
- Opened: [#9476](https://github.com/triton-lang/triton/pull/9476) [AMD] Disable True16 for assembler on gfx11 (#9447) (@jataylo)
- Opened: [#9448](https://github.com/triton-lang/triton/pull/9448) [AMD] Add enableMISched option to MIR swap pipeline (@tyb0807)
- Opened: [#9447](https://github.com/triton-lang/triton/pull/9447) [AMD] Disable True16 for assembler on gfx11 (@ptrojahn)
- Merged: [#8464](https://github.com/triton-lang/triton/pull/8464) [AMD] Optimize address increments for buffer loads in loops (@alefimov-amd)
- Merged: [#9374](https://github.com/triton-lang/triton/pull/9374) Reapply "[AMD] Introduce PartitionedSharedEncodingAttr" (#93 (@plognjen)
- Merged: [#9442](https://github.com/triton-lang/triton/pull/9442) [AMD][BACKEND] Fix OOM bug in pipelining with padded layout  (@pabloantoniom)
- Merged: [#9302](https://github.com/triton-lang/triton/pull/9302) [AMD][gfx1250] Support TDM in software pipelining  (@yangshuxin)

### migraphx
- Opened: [#4619](https://github.com/ROCm/AMDMIGraphX/pull/4619) AIMIGRAPHX-578 Reintroduce blaze for better ref gemm perform (@kahmed10)
- Opened: [#4620](https://github.com/ROCm/AMDMIGraphX/pull/4620) [AIMIGRAPHX-542] implement argmin and argmax as reduce ops (@bdevorem)
- Opened: [#4616](https://github.com/ROCm/AMDMIGraphX/pull/4616) [AIMIGRAPHX-544] Parallel compilation for dynamic graphs (@shivadbhavsar)
- Opened: [#4617](https://github.com/ROCm/AMDMIGraphX/pull/4617) Fuse GQA local window as kv-cache attention (@turneram)
- Opened: [#4613](https://github.com/ROCm/AMDMIGraphX/pull/4613) [7.2.1] Backport Inference Server improvements (@causten)
- Opened: [#4614](https://github.com/ROCm/AMDMIGraphX/pull/4614) Onnxruntime Weekly Sync 2026-02-13 (@github-actions[bot])
- Opened: [#4621](https://github.com/ROCm/AMDMIGraphX/pull/4621) [AIMIGRAPHX-571] Rewrite convolutions to GEMMs for constant  (@eddieliao)
- Opened: [#4615](https://github.com/ROCm/AMDMIGraphX/pull/4615) rocMLIR Weekly Sync 2026-02-15 (@github-actions[bot])
- Merged: [#4609](https://github.com/ROCm/AMDMIGraphX/pull/4609) Propagate constant optimization (@pnikolic-amd)
- Merged: [#4410](https://github.com/ROCm/AMDMIGraphX/pull/4410) clamping the scale (@aarushjain29)
- Merged: [#4510](https://github.com/ROCm/AMDMIGraphX/pull/4510) [BugFix] - Fix tile byte size overflow for LDS memory when p (@ivarusic-amd)
- Merged: [#4362](https://github.com/ROCm/AMDMIGraphX/pull/4362) disable matching for dynamic shapes (@shivadbhavsar)
- Merged: [#4443](https://github.com/ROCm/AMDMIGraphX/pull/4443) [AIMIGRAPHX-326] Fix "reduce_sum: axes: value out of range"  (@pfultz2)
- Merged: [#4445](https://github.com/ROCm/AMDMIGraphX/pull/4445) Show attributes in onnx trace (@pfultz2)
- Merged: [#4393](https://github.com/ROCm/AMDMIGraphX/pull/4393) Flash decoding round 1; AIMIGRAPHX-242 (@bdevorem)
- Merged: [#4396](https://github.com/ROCm/AMDMIGraphX/pull/4396) Refactor GroupQueryAttention (@turneram)
- Merged: [#4600](https://github.com/ROCm/AMDMIGraphX/pull/4600) Have eliminate_pad skip over non-constant padding, ref tests (@CharlieL7)
- Merged: [#4610](https://github.com/ROCm/AMDMIGraphX/pull/4610) Fix bug in gather rewrite with nhwc shapes (@pfultz2)

### aiter
- Opened: [#2056](https://github.com/ROCm/aiter/pull/2056) Enabling FPMX4 GEMM on non-FPMX4 devices (Navi31 in particul (@ekuznetsov139)
- Opened: [#2067](https://github.com/ROCm/aiter/pull/2067) Amd/satya/gluon/gemm mxfp4 (@Boss2002n)
- Opened: [#2066](https://github.com/ROCm/aiter/pull/2066) [TRITON] Sage attention v2: Q*K in mxfp4 (@juuso-oskari)
- Opened: [#2064](https://github.com/ROCm/aiter/pull/2064) Adding double buffer option to cross_device_reduce_1stage (@RichardChamberlain1)
- Opened: [#2062](https://github.com/ROCm/aiter/pull/2062) Add ENABLE_CK=0 build option for Triton-only builds (@sunway513)
- Opened: [#2060](https://github.com/ROCm/aiter/pull/2060) GFX1250 Kernels - GEMMa8w8 blockscale (@amirumoAMD)
- Opened: [#2053](https://github.com/ROCm/aiter/pull/2053) Support per_block for Pa PS (@ZhangLirong-amd)
- Opened: [#2055](https://github.com/ROCm/aiter/pull/2055) Silence certain warnings stemming from CK (@Micky774)
- Opened: [#2052](https://github.com/ROCm/aiter/pull/2052) Prepare repository for size optimization (@sunway513)
- Opened: [#2050](https://github.com/ROCm/aiter/pull/2050) Add Model Benchmarking Tool (@lucas-santos-amd)
- Opened: [#2065](https://github.com/ROCm/aiter/pull/2065) revert triton gemm kernel config due to core dump. (@Duyi-Wang)
- Opened: [#2057](https://github.com/ROCm/aiter/pull/2057) hotfix a8w8 gemm config (@valarLip)
- Merged: [#2034](https://github.com/ROCm/aiter/pull/2034) Top-K Top-P Sampling Kernel Optimization (@aryaman-gupta)
- Merged: [#1954](https://github.com/ROCm/aiter/pull/1954) feat(ck_tile): add a8w8 blockscale gemm with preshuffleB sup (@kensclin)
- Merged: [#2048](https://github.com/ROCm/aiter/pull/2048) [Gluon] Unified Attention 3D development for gfx12 (@k50112113)
- Merged: [#2016](https://github.com/ROCm/aiter/pull/2016) tune triton gemm kernel for MI355 DSV3 DP+EP configuration (@inkcherry)
- Merged: [#2040](https://github.com/ROCm/aiter/pull/2040) [OPUS] enhance opus UT by adding more tests (@carlushuang)
- Merged: [#2045](https://github.com/ROCm/aiter/pull/2045) [TRITON] fav3 sage optmization (@Chi-Chu319)
- Merged: [#2041](https://github.com/ROCm/aiter/pull/2041) Rocking/fix benchmark mha fwd (@rocking5566)

### atom
- Opened: [#226](https://github.com/ROCm/ATOM/pull/226) Enable Triton MOE for MXFP4 on gfx950 (MI355X) (@sunway513)
- Opened: [#225](https://github.com/ROCm/ATOM/pull/225) Add FlyDSL MOE backend and Triton fallback for FP8 MoE (@sunway513)
- Opened: [#212](https://github.com/ROCm/ATOM/pull/212) Fix CI container name collision for parallel matrix jobs (@sunway513)
- Opened: [#224](https://github.com/ROCm/ATOM/pull/224) Add Dockerfile.clean + fix linear.py shard_offset bug (@sunway513)
- Opened: [#223](https://github.com/ROCm/ATOM/pull/223) Add Quark GLM4.7-MXFP4 support (@thpereir)
- Opened: [#220](https://github.com/ROCm/ATOM/pull/220) Enable Triton MXFP4 MoE on gfx950 for GPT-OSS (@ChuanLi1101)
- Opened: [#222](https://github.com/ROCm/ATOM/pull/222) Fix prefix caching crash: recalculate num_new_tokens after b (@ChuanLi1101)
- Opened: [#218](https://github.com/ROCm/ATOM/pull/218) Enable AllReduce+RMSNorm fusion for GPT-OSS model (@ChuanLi1101)
- Opened: [#219](https://github.com/ROCm/ATOM/pull/219) mtp refine (@valarLip)
- Opened: [#217](https://github.com/ROCm/ATOM/pull/217) Kill all Docker containers before 8gpu workloads launch (@okakarpa)
- Opened: [#216](https://github.com/ROCm/ATOM/pull/216) Revert PR #215: Remove kill-containers workflow (@okakarpa)
- Opened: [#215](https://github.com/ROCm/ATOM/pull/215) Add workflow to kill Docker containers and check ROCm on MI3 (@okakarpa)
- Opened: [#214](https://github.com/ROCm/ATOM/pull/214) Revert PR #213: Remove kill-containers workflow (@okakarpa)
- Opened: [#213](https://github.com/ROCm/ATOM/pull/213) Add workflow to kill Docker containers and check ROCm on MI3 (@okakarpa)
- Opened: [#211](https://github.com/ROCm/ATOM/pull/211) Print debug logs for inference workload (@dhonnappa-amd)
- Merged: [#204](https://github.com/ROCm/ATOM/pull/204) Add GPU-free unit test suite for core engine components (@sunway513)
- Merged: [#171](https://github.com/ROCm/ATOM/pull/171) Support Qwen3-Next on ATOM Framework (@PerryZhang01)
- Merged: [#209](https://github.com/ROCm/ATOM/pull/209) Fix exclude layer (@ZhangLirong-amd)

### mori
- Opened: [#172](https://github.com/ROCm/mori/pull/172) Feat: Enable async kernel BF16 cast to FP8 combine (@isytwu)
- Opened: [#171](https://github.com/ROCm/mori/pull/171) Fix: support runtime hidden_dim for dispatch/combine (@isytwu)
- Opened: [#170](https://github.com/ROCm/mori/pull/170) Optimize: EP4 intranode kernel for FP4 dispatch + FP8 combin (@jhchouuu)
- Merged: [#169](https://github.com/ROCm/mori/pull/169) Feat: Enable intra-node FP4 dispatch and BF16 cast to FP8 co (@isytwu)

### flydsl
- Opened: [#139](https://github.com/ROCm/FlyDSL/pull/139) optimize buffer_load lds pipeline. Now it can interleave wit (@yadaish)
- Opened: [#133](https://github.com/ROCm/FlyDSL/pull/133) Add Flash Attention forward kernel with MFMA32 register pipe (@yanguahe)
- Opened: [#138](https://github.com/ROCm/FlyDSL/pull/138) refactor the arch check related to bf16 global atomics for e (@hongxiayang)
- Opened: [#137](https://github.com/ROCm/FlyDSL/pull/137) add declaimer (@hongxiayang)
- Opened: [#136](https://github.com/ROCm/FlyDSL/pull/136) fix N/A SKU and replace it with gfx for gpu information in r (@hongxiayang)
- Opened: [#132](https://github.com/ROCm/FlyDSL/pull/132) fix a4w4 test (@coderfeli)
- Merged: [#129](https://github.com/ROCm/FlyDSL/pull/129) [MoE] simplify moe reduce kernel & add zero buffer flag (@aoli26)
- Merged: [#98](https://github.com/ROCm/FlyDSL/pull/98) fix a4w4 gemm precision (@zhiding512)

## New Issues This Week

### pytorch
- [#175372](https://github.com/pytorch/pytorch/issues/175372) python property setter ignored when assigning nn.Parameter() (@profPlum)
- [#175058](https://github.com/pytorch/pytorch/issues/175058) torch.compile VRAM usage regression between 2.9.1 and 2.10.0 (@dxqb)
- [#175368](https://github.com/pytorch/pytorch/issues/175368) `F.embedding_bag` segfaults when intermediate offsets exceed (@SilentTester73)
- [#175370](https://github.com/pytorch/pytorch/issues/175370) `F.embedding_bag` segfaults with float64 weight and empty of (@SilentTester73)
- [#175354](https://github.com/pytorch/pytorch/issues/175354) DISABLED test_comprehensive_nn_functional_linear_cuda_float3 (@mlazos)
- [#174985](https://github.com/pytorch/pytorch/issues/174985) `torch.isclose` fails with a broadcast when comparing with ` (@SilentTester73)
- [#174949](https://github.com/pytorch/pytorch/issues/174949) [vllm] CUBLAS_STATUS_INVALID_VALUE in cublasGemmEx after upg (@ZJY0516)
- [#175325](https://github.com/pytorch/pytorch/issues/175325) Incorrect storage offsets propagation in inductor with as_st (@Rakul-Chauhan)
- [#175189](https://github.com/pytorch/pytorch/issues/175189) [MPS] BatchNorm2d backward produces wildly wrong weight grad (@npinto)
- [#175190](https://github.com/pytorch/pytorch/issues/175190) [MPS] AvgPool2d/AdaptiveAvgPool2d backward crashes (SIGABRT) (@npinto)
- [#175211](https://github.com/pytorch/pytorch/issues/175211) CUDA/ROCm/Accelerator testing should replace get_device_capa (@jeffdaily)
- [#175160](https://github.com/pytorch/pytorch/issues/175160) check if file exsits before hipifying (@trixirt)
- [#174984](https://github.com/pytorch/pytorch/issues/174984) `torch.fft.rfft` errors out with MKL FFT error when given an (@SilentTester73)

### vllm
- [#34943](https://github.com/vllm-project/vllm/issues/34943) [CI Failure]: AMD Samplers Test (mi325_1) (@varun-sundar-rabindranath)
- [#34939](https://github.com/vllm-project/vllm/issues/34939) [CI Failure]: V1 e2e + engine : Cannot re-initialize CUDA in (@varun-sundar-rabindranath)
- [#34752](https://github.com/vllm-project/vllm/issues/34752) [Bug]: Improve `--kv-cache-dtype` behavior when checkpoint s (@pavanimajety)
- [#34851](https://github.com/vllm-project/vllm/issues/34851) [Feature]: Refactor Quark MoE and mxfp4 MoE to align with Mo (@BowenBao)
- [#34812](https://github.com/vllm-project/vllm/issues/34812) [Bug]: GraniteMoeHybridModel not applying embedding_multipli (@gabe-l-hart)
- [#34859](https://github.com/vllm-project/vllm/issues/34859) [Bug]: missing shards from quantized checkpoint fails silent (@andrea-fasoli)
- [#34886](https://github.com/vllm-project/vllm/issues/34886) [Bug]: #32618 performance issue (@gengchaogit)
- [#34817](https://github.com/vllm-project/vllm/issues/34817) [Bug]: Trying to run gpt-oss-120b on rtx pro 6000 (@chadbek)
- [#34759](https://github.com/vllm-project/vllm/issues/34759) [Bug]: nvidia/Llama-3.3-70B-Instruct-NVFP4 Degraded / Gibber (@frankwang28)
- [#34619](https://github.com/vllm-project/vllm/issues/34619) [Bug]: Qwen3.5. `illegal memory access` (@vadiklyutiy)
- [#34755](https://github.com/vllm-project/vllm/issues/34755) Qwen3-Coder-Next-FP8 with tool calling causes system hard-fr (@zaidorx)
- [#34583](https://github.com/vllm-project/vllm/issues/34583) [Bug] Missing Vocabulary Validation for MTP and Eagle Specul (@amadhan882)
- [#34573](https://github.com/vllm-project/vllm/issues/34573) [Installation/Runtime]: Linux ROCM7 /  RuntimeError: No HIP  (@NickJLange)
- [#34650](https://github.com/vllm-project/vllm/issues/34650) Bug: Speculative Decoding (MTP) Causes </think> Detection Fa (@cicirori)
- [#34607](https://github.com/vllm-project/vllm/issues/34607) [Bug]: specualative decoding error in 0.15.1 (@hocop)

### sglang
- [#19031](https://github.com/sgl-project/sglang/issues/19031) [Feature] ROCm nightly in upstream lmsysorg docker org (@functionstackx)
- [#19028](https://github.com/sgl-project/sglang/issues/19028) [Bug] GLM5 nightly Mi355 broken due to transformer dependenc (@functionstackx)

### migraphx
- [#4618](https://github.com/ROCm/AMDMIGraphX/issues/4618) [Issue]: MIGraphX Dynamic Shape Issue ONNXRuntime (@DiarmuidKelly)

### aiter
- [#2061](https://github.com/ROCm/aiter/issues/2061) [Bug] Custom all-reduce IPC buffers use fixed VA, conflict w (@jhinpan)
- [#2059](https://github.com/ROCm/aiter/issues/2059) [Issue]: GLM-5 aiter fused_moe with SGLang + MI355 (@ozziemoreno)
- [#2054](https://github.com/ROCm/aiter/issues/2054) [Feature]: Migrate Python bindings from pybind11 to apache-t (@carlushuang)

### atom
- [#221](https://github.com/ROCm/ATOM/issues/221) [Issue]: ATOM fails on Qwen3 model when the flag "--enable_p (@vecheruk-amd)
