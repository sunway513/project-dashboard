{
  "collected_at": "2026-02-20T08:13:54Z",
  "issues": [
    {
      "number": 175372,
      "title": "python property setter ignored when assigning nn.Parameter() to nn.Module",
      "author": "profPlum",
      "state": "open",
      "created_at": "2026-02-19T22:48:07Z",
      "updated_at": "2026-02-20T07:29:00Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175372",
      "labels": [
        "module: nn",
        "triaged",
        "bot-triaged"
      ]
    },
    {
      "number": 174417,
      "title": "[release 2.11] [triton] test/inductor/test_loop_ordering.py::LoopOrderingTest::test_fp8_cast_and_t",
      "author": "atalman",
      "state": "open",
      "created_at": "2026-02-05T20:47:03Z",
      "updated_at": "2026-02-20T06:09:20Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174417",
      "labels": [
        "triaged",
        "oncall: pt2",
        "module: inductor",
        "upstream triton",
        "module: floatx (formerly float8)",
        "bot-triaged"
      ]
    },
    {
      "number": 175058,
      "title": "torch.compile VRAM usage regression between 2.9.1 and 2.10.0",
      "author": "dxqb",
      "state": "open",
      "created_at": "2026-02-15T17:14:00Z",
      "updated_at": "2026-02-20T03:07:42Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175058",
      "labels": [
        "high priority",
        "triage review",
        "needs reproduction",
        "module: memory usage",
        "oncall: pt2"
      ]
    },
    {
      "number": 173772,
      "title": "Tensors wrapped by torch.distributed._coalescing_manager cannot be released normally",
      "author": "lhb8125",
      "state": "open",
      "created_at": "2026-01-29T06:13:11Z",
      "updated_at": "2026-02-20T00:46:42Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/173772",
      "labels": [
        "oncall: distributed",
        "triaged",
        "module: c10d"
      ]
    },
    {
      "number": 175368,
      "title": "`F.embedding_bag` segfaults when intermediate offsets exceed indices length",
      "author": "SilentTester73",
      "state": "open",
      "created_at": "2026-02-19T22:32:12Z",
      "updated_at": "2026-02-19T23:45:12Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175368",
      "labels": [
        "triage review",
        "module: nn",
        "module: empty tensor",
        "topic: fuzzer",
        "bot-triaged"
      ]
    },
    {
      "number": 175370,
      "title": "`F.embedding_bag` segfaults with float64 weight and empty offsets",
      "author": "SilentTester73",
      "state": "open",
      "created_at": "2026-02-19T22:33:53Z",
      "updated_at": "2026-02-19T23:44:36Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175370",
      "labels": [
        "triage review",
        "module: crash",
        "module: cpu",
        "module: embedding",
        "module: empty tensor",
        "topic: fuzzer",
        "bot-triaged"
      ]
    },
    {
      "number": 174379,
      "title": "[Inductor][PyTorch 2.10] RuntimeError in native_layer_norm_backward with dynamic shapes. Generated inductor code computes incorrect workspace slice.",
      "author": "sssupik",
      "state": "open",
      "created_at": "2026-02-05T14:14:09Z",
      "updated_at": "2026-02-19T23:42:56Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174379",
      "labels": [
        "module: crash",
        "triaged",
        "oncall: pt2",
        "module: dynamic shapes",
        "module: inductor",
        "PT2-Bug-Bash"
      ]
    },
    {
      "number": 172747,
      "title": "`torch.compile` silent bug in GGUF dequant, possibly because of `view(dtype)`",
      "author": "woct0rdho",
      "state": "open",
      "created_at": "2026-01-18T16:12:15Z",
      "updated_at": "2026-02-19T23:25:51Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/172747",
      "labels": [
        "high priority",
        "triage review",
        "oncall: pt2",
        "module: dynamic shapes",
        "module: inductor"
      ]
    },
    {
      "number": 172668,
      "title": "Pipeline communication blocks the execution of pipeline stages",
      "author": "yuankaichen-amd",
      "state": "open",
      "created_at": "2026-01-16T19:57:05Z",
      "updated_at": "2026-02-19T22:44:00Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/172668",
      "labels": [
        "high priority",
        "triage review",
        "oncall: distributed",
        "pipeline parallelism"
      ]
    },
    {
      "number": 169058,
      "title": "[MPS] Inconsistent overflow behavior when casting Float to Int8 compared to CPU/CUDA (Saturation vs Wraparound)",
      "author": "lingebeng",
      "state": "open",
      "created_at": "2025-11-25T14:05:43Z",
      "updated_at": "2026-02-19T22:18:23Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/169058",
      "labels": [
        "low priority",
        "triaged",
        "module: edge cases",
        "module: mps"
      ]
    },
    {
      "number": 167636,
      "title": "TorchDynamo Compilation Error: Invalid Stride Handling for FFT in Custom Model During Compilation",
      "author": "Blooming-Tree",
      "state": "open",
      "created_at": "2025-11-12T11:34:05Z",
      "updated_at": "2026-02-19T21:56:35Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/167636",
      "labels": [
        "triaged",
        "module: fft",
        "oncall: pt2",
        "module: inductor"
      ]
    },
    {
      "number": 174794,
      "title": "REGRESSION: Shadowed variable name crashes `torch.compile` in `2.10` (not `2.9`)",
      "author": "rwkeane",
      "state": "open",
      "created_at": "2026-02-11T19:01:05Z",
      "updated_at": "2026-02-19T21:55:18Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174794",
      "labels": [
        "triaged",
        "oncall: pt2",
        "module: dynamo"
      ]
    },
    {
      "number": 167901,
      "title": "nvalid _global_ write of size 16 bytes in torch.bmm with sparse tensors",
      "author": "supermarkli",
      "state": "open",
      "created_at": "2025-11-15T03:25:41Z",
      "updated_at": "2026-02-19T21:52:28Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/167901",
      "labels": [
        "module: sparse",
        "module: cuda",
        "triaged",
        "module: sanitizers"
      ]
    },
    {
      "number": 173800,
      "title": "[release 2.11] [triton]  test_aot_inductor_package.py::TestAOTInductorPackageCpp_cuda::test_compile_with_exporter",
      "author": "atalman",
      "state": "open",
      "created_at": "2026-01-29T15:08:52Z",
      "updated_at": "2026-02-19T21:03:14Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/173800",
      "labels": [
        "triaged",
        "oncall: pt2",
        "module: inductor",
        "upstream triton"
      ]
    },
    {
      "number": 77764,
      "title": "General MPS op coverage tracking issue",
      "author": "albanD",
      "state": "open",
      "created_at": "2022-05-18T18:12:47Z",
      "updated_at": "2026-02-19T20:45:47Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/77764",
      "labels": [
        "feature",
        "triaged",
        "tracker",
        "module: mps"
      ]
    },
    {
      "number": 173659,
      "title": "DataDependentOutputException: aten.equal.default when exporting torch.quantile",
      "author": "DLumi",
      "state": "open",
      "created_at": "2026-01-28T16:12:44Z",
      "updated_at": "2026-02-19T20:03:12Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/173659",
      "labels": [
        "high priority",
        "triaged",
        "oncall: pt2",
        "module: dynamic shapes",
        "oncall: export"
      ]
    },
    {
      "number": 175354,
      "title": "DISABLED test_comprehensive_nn_functional_linear_cuda_float32 (__main__.TestInductorOpInfoCUDA)",
      "author": "mlazos",
      "state": "open",
      "created_at": "2026-02-19T19:49:20Z",
      "updated_at": "2026-02-19T19:50:03Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175354",
      "labels": [
        "high priority",
        "triage review",
        "skipped",
        "oncall: pt2",
        "module: inductor"
      ]
    },
    {
      "number": 138343,
      "title": "DISABLED test_cuda_load (__main__.TestCUDACodeCache)",
      "author": "huydhn",
      "state": "open",
      "created_at": "2024-10-18T17:42:58Z",
      "updated_at": "2026-02-19T19:27:09Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/138343",
      "labels": [
        "high priority",
        "triaged",
        "skipped",
        "oncall: pt2",
        "module: inductor"
      ]
    },
    {
      "number": 135892,
      "title": "torch.compile with mode = \"max-autotune\" breaks when starting from inference_mode",
      "author": "JanRocketMan",
      "state": "open",
      "created_at": "2024-09-12T20:50:32Z",
      "updated_at": "2026-02-19T19:19:10Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/135892",
      "labels": [
        "high priority",
        "triaged",
        "module: cuda graphs",
        "inference mode",
        "oncall: pt2"
      ]
    },
    {
      "number": 115388,
      "title": "`torch.distributed.destroy_process_group()` hangs after CUDA graph capture of NCCL operations",
      "author": "cbcase",
      "state": "open",
      "created_at": "2023-12-07T23:01:16Z",
      "updated_at": "2026-02-19T19:17:35Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/115388",
      "labels": [
        "triage review",
        "oncall: distributed",
        "module: c10d",
        "module: cuda graphs"
      ]
    },
    {
      "number": 173702,
      "title": "[RFC] Release 2.11 and 2.12 Triton update",
      "author": "atalman",
      "state": "open",
      "created_at": "2026-01-28T21:09:55Z",
      "updated_at": "2026-02-19T18:48:42Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/173702",
      "labels": [
        "triaged",
        "oncall: pt2",
        "module: inductor",
        "upstream triton",
        "bot-triaged"
      ]
    },
    {
      "number": 174282,
      "title": "triu_tril_kernel causes HSA_STATUS_ERROR_MEMORY_APERTURE_VIOLATION on AMD MI210/MI300X with FP16 tensors",
      "author": "Medhatt21",
      "state": "open",
      "created_at": "2026-02-04T14:14:32Z",
      "updated_at": "2026-02-19T17:19:36Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174282",
      "labels": [
        "module: crash",
        "module: rocm",
        "triaged",
        "module: half",
        "bot-triaged"
      ]
    },
    {
      "number": 174985,
      "title": "`torch.isclose` fails with a broadcast when comparing with `equal_nan=True`.",
      "author": "SilentTester73",
      "state": "open",
      "created_at": "2026-02-13T18:56:27Z",
      "updated_at": "2026-02-19T16:57:06Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174985",
      "labels": [
        "triaged",
        "actionable",
        "module: python frontend",
        "module: edge cases",
        "topic: fuzzer",
        "bot-triaged",
        "bot-mislabeled"
      ]
    },
    {
      "number": 174949,
      "title": "[vllm] CUBLAS_STATUS_INVALID_VALUE in cublasGemmEx after upgrading to PyTorch 2.10",
      "author": "ZJY0516",
      "state": "open",
      "created_at": "2026-02-13T07:20:37Z",
      "updated_at": "2026-02-19T16:01:04Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174949",
      "labels": [
        "module: cuda",
        "triaged",
        "module: cublas",
        "module: vllm"
      ]
    },
    {
      "number": 174555,
      "title": "Profiler chrome traces express record_function and profiler step incorrectly when using with_stack=True",
      "author": "MichaelJFishman",
      "state": "open",
      "created_at": "2026-02-08T16:55:57Z",
      "updated_at": "2026-02-19T14:12:26Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174555",
      "labels": [
        "oncall: profiler",
        "bot-triaged"
      ]
    },
    {
      "number": 173164,
      "title": "allgather throw exception with discontigous input tensor",
      "author": "gotorion",
      "state": "open",
      "created_at": "2026-01-23T09:22:33Z",
      "updated_at": "2026-02-19T14:06:26Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/173164",
      "labels": [
        "oncall: distributed"
      ]
    },
    {
      "number": 175325,
      "title": "Incorrect storage offsets propagation in inductor with as_strided",
      "author": "Rakul-Chauhan",
      "state": "open",
      "created_at": "2026-02-19T10:55:01Z",
      "updated_at": "2026-02-19T10:55:05Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175325",
      "labels": [
        "oncall: pt2"
      ]
    },
    {
      "number": 175189,
      "title": "[MPS] BatchNorm2d backward produces wildly wrong weight gradients on channels_last inputs",
      "author": "npinto",
      "state": "open",
      "created_at": "2026-02-17T21:12:50Z",
      "updated_at": "2026-02-19T06:22:20Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175189",
      "labels": [
        "triage review",
        "module: autograd",
        "has workaround",
        "module: memory format",
        "module: correctness (silent)",
        "module: norms and normalization",
        "module: mps",
        "bot-triaged"
      ]
    },
    {
      "number": 175190,
      "title": "[MPS] AvgPool2d/AdaptiveAvgPool2d backward crashes (SIGABRT) on channels_last inputs",
      "author": "npinto",
      "state": "open",
      "created_at": "2026-02-17T21:13:32Z",
      "updated_at": "2026-02-19T06:22:18Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175190",
      "labels": [
        "triage review",
        "module: crash",
        "module: autograd",
        "module: nn",
        "module: memory format",
        "module: pooling",
        "module: mps",
        "bot-triaged"
      ]
    },
    {
      "number": 51856,
      "title": "Assignment target is transposed when using jit.script and avanced indexing",
      "author": "nlgranger",
      "state": "open",
      "created_at": "2021-02-07T11:13:42Z",
      "updated_at": "2026-02-18T19:46:05Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/51856",
      "labels": [
        "oncall: jit",
        "good first issue",
        "OSS contribution wanted",
        "days"
      ]
    },
    {
      "number": 150296,
      "title": "[RFC] zentorch Integration",
      "author": "naveenthangudu",
      "state": "open",
      "created_at": "2025-03-31T12:46:40Z",
      "updated_at": "2026-02-18T18:45:35Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/150296",
      "labels": [
        "triaged",
        "oncall: pt2",
        "module: inductor",
        "release-feature-request"
      ]
    },
    {
      "number": 64947,
      "title": "Quantile is limited to 16 million elements and have poor performance.",
      "author": "DrDryg",
      "state": "open",
      "created_at": "2021-09-13T19:14:20Z",
      "updated_at": "2026-02-18T17:23:35Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/64947",
      "labels": [
        "module: performance",
        "triaged",
        "module: numpy",
        "actionable",
        "module: sorting and selection"
      ]
    },
    {
      "number": 138652,
      "title": "AOT eager accuracy regression in Segformer in 2.5.0 release",
      "author": "playertr",
      "state": "open",
      "created_at": "2024-10-22T22:32:43Z",
      "updated_at": "2026-02-18T16:44:41Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/138652",
      "labels": [
        "high priority",
        "triaged",
        "oncall: pt2",
        "module: aotdispatch",
        "module: pt2-dispatcher",
        "PT2-Bug-Bash"
      ]
    },
    {
      "number": 158212,
      "title": "wrong gradients with compiled flex attention",
      "author": "tsengalb99",
      "state": "open",
      "created_at": "2025-07-14T03:44:01Z",
      "updated_at": "2026-02-18T05:07:40Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/158212",
      "labels": [
        "high priority",
        "triaged",
        "oncall: pt2",
        "upstream triton",
        "module: higher order operators",
        "module: flex attention"
      ]
    },
    {
      "number": 24422,
      "title": "Label tracking meta-issue (edit me to get automatically CC'ed on issues! cc bot)",
      "author": "ezyang",
      "state": "open",
      "created_at": "2019-08-15T18:28:22Z",
      "updated_at": "2026-02-18T05:03:54Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/24422",
      "labels": [
        "triaged"
      ]
    },
    {
      "number": 175211,
      "title": "CUDA/ROCm/Accelerator testing should replace get_device_capability() with feature queries",
      "author": "jeffdaily",
      "state": "open",
      "created_at": "2026-02-18T00:22:38Z",
      "updated_at": "2026-02-18T00:24:15Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175211",
      "labels": [
        "feature",
        "module: cuda",
        "module: rocm",
        "module: tests",
        "triaged",
        "module: accelerator",
        "bot-triaged"
      ]
    },
    {
      "number": 160230,
      "title": "Offer official Pytorch Vulkan backend on pytorch.org",
      "author": "alshdavid",
      "state": "open",
      "created_at": "2025-08-08T23:19:51Z",
      "updated_at": "2026-02-18T00:11:26Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/160230",
      "labels": [
        "feature",
        "triaged",
        "needs research",
        "module: vulkan"
      ]
    },
    {
      "number": 166001,
      "title": "`torch.onnx.export`'s `dynamic_shape` should take renamed inputs into account",
      "author": "mqudsi",
      "state": "open",
      "created_at": "2025-10-21T16:36:24Z",
      "updated_at": "2026-02-17T23:10:52Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/166001",
      "labels": [
        "module: onnx",
        "low priority",
        "triaged",
        "OSS contribution wanted"
      ]
    },
    {
      "number": 172026,
      "title": "`torch.compile(torch.func.vjp)` crashes when creating a new `Tensor`",
      "author": "rwkeane",
      "state": "open",
      "created_at": "2026-01-08T20:51:10Z",
      "updated_at": "2026-02-17T18:53:05Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/172026",
      "labels": [
        "module: autograd",
        "triaged",
        "oncall: pt2",
        "module: functorch"
      ]
    },
    {
      "number": 156649,
      "title": "[dynamo] torch.randint_like on DTensor does not work with compile",
      "author": "nathan-az",
      "state": "open",
      "created_at": "2025-06-23T22:23:02Z",
      "updated_at": "2026-02-17T18:17:53Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/156649",
      "labels": [
        "oncall: distributed",
        "triaged",
        "oncall: pt2",
        "module: dynamo",
        "module: dtensor"
      ]
    },
    {
      "number": 175160,
      "title": "check if file exsits before hipifying",
      "author": "trixirt",
      "state": "open",
      "created_at": "2026-02-17T17:06:10Z",
      "updated_at": "2026-02-17T17:07:49Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/175160",
      "labels": [
        "module: build",
        "module: rocm",
        "triaged",
        "module: third_party",
        "bot-triaged"
      ]
    },
    {
      "number": 174682,
      "title": "spin lint doesn't regenerate cuda headers",
      "author": "albanD",
      "state": "open",
      "created_at": "2026-02-10T15:57:22Z",
      "updated_at": "2026-02-17T16:52:13Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174682",
      "labels": [
        "module: build",
        "module: lint",
        "triaged",
        "bot-triaged",
        "module: spin"
      ]
    },
    {
      "number": 148752,
      "title": "Compiling Flex Attention on CPU: torch._inductor.exc.InductorError: IndexError: tuple index out of range",
      "author": "JCBrouwer",
      "state": "open",
      "created_at": "2025-03-07T11:03:25Z",
      "updated_at": "2026-02-17T12:50:36Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/148752",
      "labels": [
        "module: intel",
        "oncall: pt2",
        "module: higher order operators",
        "oncall: cpu inductor",
        "module: pt2-dispatcher",
        "module: flex attention"
      ]
    },
    {
      "number": 166930,
      "title": "[DTensor] DTensor randn inconsistent with single device behavior",
      "author": "sichu2023",
      "state": "open",
      "created_at": "2025-11-04T05:58:26Z",
      "updated_at": "2026-02-17T03:34:03Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/166930",
      "labels": [
        "oncall: distributed"
      ]
    },
    {
      "number": 150168,
      "title": "[ROCm] PyTorch slow on TTS",
      "author": "winstonma",
      "state": "open",
      "created_at": "2025-03-28T07:38:47Z",
      "updated_at": "2026-02-16T17:47:40Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/150168",
      "labels": [
        "module: rocm",
        "triaged"
      ]
    },
    {
      "number": 171119,
      "title": "DISABLED test_index (__main__.DistTensorOpsTest)",
      "author": "jeffdaily",
      "state": "open",
      "created_at": "2025-12-22T19:46:23Z",
      "updated_at": "2026-02-16T16:55:12Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/171119",
      "labels": [
        "module: rocm",
        "triaged",
        "skipped",
        "rocm-skipped-tests"
      ]
    },
    {
      "number": 174984,
      "title": "`torch.fft.rfft` errors out with MKL FFT error when given an empty tensor",
      "author": "SilentTester73",
      "state": "open",
      "created_at": "2026-02-13T18:51:12Z",
      "updated_at": "2026-02-16T10:47:32Z",
      "html_url": "https://github.com/pytorch/pytorch/issues/174984",
      "labels": [
        "triage review",
        "module: error checking",
        "actionable",
        "module: fft",
        "module: intel",
        "module: edge cases",
        "module: empty tensor",
        "topic: fuzzer",
        "bot-triaged"
      ]
    }
  ]
}